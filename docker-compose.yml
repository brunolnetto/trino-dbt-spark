version: "3.9"

services:
      
  de_psql:
    image: postgres:15
    container_name: de_psql
    healthcheck:
        test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}", "-d", "${POSTGRES_DB}"]
        interval: 10s
        timeout: 5s
        retries: 5
        start_period: 30s
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-postgres}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      METABASE_DB: ${METABASE_DB:-metabase}
      METABASE_DB_USER: ${METABASE_DB_USER:-metabase}
      METABASE_DB_PASSWORD: ${METABASE_DB_PASSWORD:-metabase123}
    volumes:
      - psql_data:/var/lib/postgresql/data
      - ./docker/psql/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh:ro
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    env_file:
      - .env
    networks:
      - data_network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
        reservations:
          memory: 1G
          cpus: '1'

  minio:
    hostname: minio
    image: "minio/minio"
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: [ "server", "/data", "--console-address", ":9001" ]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - minio_data:/data
    env_file:
      - .env
    networks:
      - data_network

  hive-metastore:
    build:
      context: ./docker/hive-metastore
      dockerfile: ./Dockerfile
    container_name: hive-metastore
    hostname: hive-metastore    
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    healthcheck:
      test: 
        - "CMD-SHELL"
        - |
          jps | grep -q 'RunJar' && 
          nc -z localhost 9083 && 
          wget -q -O- http://localhost:9083 || exit 1
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    ports:
      - "9083:9083"
    env_file:
      - .env 
    volumes:
      - ./docker/hive-metastore/conf:/opt/hive/conf
      - ./docker/hive-metastore/conf/log4j.properties:/opt/hive/conf/log4j.properties
      - hive_logs:/var/log/hive
      - metastore_logs:/var/log/metastore
      - ./warehouse:/user/hive/warehouse
    networks:
      - data_network
    depends_on:
      minio:
        condition: service_healthy

  trino:
    image: "trinodb/trino"
    container_name: trino
    hostname: trino
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'
        reservations:
          memory: 4G
          cpus: '2'
    depends_on:
      hive-metastore:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/info/state"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    ports:
      - "8080:8080"
    volumes:
      - ./docker/trino:/etc/trino
      - trino_logs:/var/log/trino
    networks:
      - data_network

  spark-master:
    build:
      context: ./docker/spark
      dockerfile: ./Dockerfile
    container_name: "spark-master"
    environment:
      - SPARK_MODE=master
      - SPARK_LOCAL_IP=spark-master
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 60s
    depends_on:
      hive-metastore:
        condition: service_healthy
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./docker/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker/spark/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
      - spark_logs:/opt/bitnami/spark/logs
      - ./docker/logrotate.conf:/etc/logrotate.d/spark
    networks:
      - data_network

  spark-worker:
    image: docker.io/bitnami/spark:3.3
    env_file:
      - .env
    volumes:
      - ./docker/spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker/spark/conf/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
      - spark_logs:/opt/bitnami/spark/logs
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081 && jps | grep -q 'Worker'"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 60s
    depends_on:
      spark-master:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    networks:
      - data_network
    deploy:
      replicas: 2

  spark-thrift-server:
    build:
      context: ./docker/spark
      dockerfile: ./Dockerfile
    container_name: "spark-thrift-server"
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 10000 && jps | grep -q 'HiveThriftServer2'"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 60s
    depends_on:
      spark-master:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
      spark-worker:
        condition: service_healthy
    ports:
      - "4040:4040"
      - "10000:10000"
    command: >
      sh -c "
        ./sbin/start-thriftserver.sh --driver-java-options '-Dhive.metastore.uris=thrift://hive-metastore:9083' --master spark://spark-master:7077
      "
    volumes:
      - ./docker/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    networks:
      - data_network

  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    hostname: metabase
    volumes:
      - /dev/urandom:/dev/random:ro
    ports:
      - 3000:3000
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: ${METABASE_DB:-metabase}
      MB_DB_PORT: ${POSTGRES_PORT:-5432}
      MB_DB_USER: ${METABASE_DB_USER:-metabase}
      MB_DB_PASS: ${METABASE_DB_PASSWORD:-metabase123}
      MB_DB_HOST: de_psql
      JAVA_TIMEZONE: ${TZ:-UTC}
    env_file:
      - .env
    networks:
      - data_network
    depends_on:
      de_psql:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
    healthcheck:
      test: curl --fail -I http://localhost:3000/api/health || exit 1
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 60s

volumes:
  psql_data:
  minio_data:
  spark_logs:
  trino_logs:
  hive_logs:
  metastore_logs:

networks:
  data_network:
    driver: bridge
    name: data_network
