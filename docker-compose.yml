services:
      
  de_psql:
    image: postgres:15
    container_name: de_psql
    healthcheck:
        test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}", "-d", "${POSTGRES_DB}"]
        interval: 10s
        timeout: 5s
        retries: 5
        start_period: 30s
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-postgres}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    volumes:
      - psql_data:/var/lib/postgresql/data
      - ./docker/psql/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh:ro
      - ./docker/psql/custom-entrypoint.sh:/usr/local/bin/custom-entrypoint.sh:ro
    entrypoint: ["/usr/local/bin/custom-entrypoint.sh"]
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    env_file:
      - .env
    networks:
      - data_network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2'
        reservations:
          memory: 1G
          cpus: '1'

  minio:
    hostname: minio
    image: "minio/minio"
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: [ "server", "/data", "--console-address", ":9001" ]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - minio_data:/data
    env_file:
      - .env
    networks:
      - data_network
  
  minio-init:
    image: minio/mc
    container_name: minio_init
    entrypoint: ["/bin/sh", "-c"]
    command: ["/scripts/minio_setup.sh"]
    env_file:
      - .env
    volumes:
      - ./docker/minio/:/scripts/:ro
    depends_on:
      minio:
        condition: service_healthy
    networks:
      - data_network

  hive-metastore:
    build:
      context: ./docker/hive-metastore
      dockerfile: ./Dockerfile
    container_name: hive-metastore
    hostname: hive-metastore    
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 9083 && echo 'Hive Metastore port 9083 is open' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
    environment:
      - HADOOP_OPTS="-Dmetastore.thrift.compact=true -Dmetastore.thrift.framed=true -Dhive.metastore.client.connect.retry.delay=5 -Dhive.server2.transport.mode=binary"
    ports:
      - "9083:9083"
    env_file:
      - .env 
    volumes:
      - ./docker/hive-metastore/conf:/opt/apache-hive-metastore-3.0.0-bin/conf
      - hive_logs:/var/log/hive
      - metastore_logs:/var/log/metastore
      - warehouse_data:/user/hive/warehouse
    networks:
      - data_network
    depends_on:
      minio:
        condition: service_healthy
      minio-init:
        condition: service_completed_successfully

  trino:
    image: "trinodb/trino:427"
    container_name: trino
    hostname: trino
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4'
        reservations:
          memory: 4G
          cpus: '2'
    depends_on:
      hive-metastore:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/info/state"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    ports:
      - "8080:8080"
    volumes:
      - ./docker/trino:/etc/trino
      - ./docker/trino/conf:/etc/trino/conf
      - trino_logs:/var/log/trino
    networks:
      - data_network

  spark-master:
    build:
      context: ./docker/spark
      dockerfile: ./Dockerfile
    container_name: "spark-master"
    environment:
      - SPARK_MODE=master
      - SPARK_LOCAL_IP=spark-master
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://$(hostname):8080 || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 60s
    depends_on:
      hive-metastore:
        condition: service_healthy
    ports:
      - "7077:7077"
      - "8081:8080"
    volumes:
      - ./docker/spark/conf/:/opt/bitnami/spark/conf/
      - spark_logs:/opt/bitnami/spark/logs
      - ./docker/logrotate.conf:/etc/logrotate.d/spark
    networks:
      - data_network

  spark-worker:
    image: docker.io/bitnami/spark:3.3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
    env_file:
      - .env
    volumes:
      - ./docker/spark/conf/:/opt/bitnami/spark/conf/
      - spark_logs:/opt/bitnami/spark/logs
    healthcheck:
      test: ["CMD-SHELL", "ps -ef | grep -v grep | grep 'org.apache.spark.deploy.worker.Worker' || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 60s
    depends_on:
      spark-master:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    networks:
      - data_network
    deploy:
      replicas: 2

  spark-thrift-server:
    build:
      context: ./docker/spark
      dockerfile: ./Dockerfile
    container_name: "spark-thrift-server"
    environment:
      - SPARK_MODE=master
      - SPARK_LOCAL_IP=spark-thrift-server
      - HOME=/opt/bitnami/spark
      - USER=spark
    user: "1001"
    healthcheck:
      test: ["CMD-SHELL", "ps -ef | grep -v grep | grep 'HiveThriftServer2' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 6
      start_period: 60s
    depends_on:
      spark-master:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    ports:
      - "4040:4040"
      - "10000:10000"
    command: >
      sh -c "
        mkdir -p /opt/bitnami/spark/.ivy2/local /opt/bitnami/spark/tmp && 
        touch /opt/bitnami/spark/tmp/nss_passwd && 
        chmod -R 777 /opt/bitnami/spark/.ivy2 /opt/bitnami/spark/tmp && 
        sleep 30 && 
        ./sbin/start-thriftserver.sh --driver-java-options '-Dhive.metastore.uris=thrift://hive-metastore:9083 -DHADOOP_USER_NAME=spark' --master spark://spark-master:7077
      "
    volumes:
      - ./docker/spark/conf/:/opt/bitnami/spark/conf/
      - spark_logs:/opt/bitnami/spark/logs
    networks:
      - data_network

  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    hostname: metabase
    volumes:
      - /dev/urandom:/dev/random:ro
    ports:
      - 3000:3000
    env_file:
      - .env
    networks:
      - data_network
    depends_on:
      de_psql:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
    healthcheck:
      test: curl --fail -I http://localhost:3000/api/health || exit 1
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 60s

volumes:
  psql_data:
  minio_data:
  spark_logs:
  trino_logs:
  hive_logs:
  metastore_logs:
  warehouse_data:

networks:
  data_network:
    driver: bridge
    name: data_network
